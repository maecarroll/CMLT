{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computational Methods for Linguistic Typology\n",
    "\n",
    "\n",
    "## Part 2 - The typological data cycle\n",
    "\n",
    "Matthew J Carroll\n",
    "\n",
    "Australian Linguistic Society 2022 CoEDL Masterclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/datascience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/typscience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setting up a work environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Folder structure w/backup & version control\n",
    "    - [Github](https://github.com/) \n",
    "    - [Cloudstor](https://cloudstor.aarnet.edu.au/)\n",
    "    - Dropbox\n",
    "    - University server\n",
    "- Documentation process\n",
    "- Programming environment (Python/R)\n",
    "    - Jupyter Notebook\n",
    "- Writing environment\n",
    "    - [Overleaf](https://www.overleaf.com/) (Latex)\n",
    "    - Google Docs \n",
    "    - Local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying a domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/typscience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Literature review\n",
    "- Defining an informal 'base' \n",
    "- Anticipating problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Verbose Exponence\n",
    "\n",
    "|Number|Form|\n",
    "|-----------|-----------|\n",
    "|SG| *wɐ-mdəd-ə* |\n",
    "|DU| *nə-mdəd-anɛ*|\n",
    "|PL|*nə-mdəd-ə*|\n",
    "\n",
    "1 PRS Partial Paradigm of yəmdədə 'to sit' in Yei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Verbose exponence**: *The expression of some category uses more component elements than strictly necessary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/typscience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='Images/data.png' width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How do we know where to look?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Images/pacific_central.jpg\" width=15000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Inferring possible candidate languages from typological knowledge\n",
    "- Conferring with colleagues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"Images/library.jpg\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**How can we speed up the grammar reading process?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 1 week to sufficiently read a grammar\n",
    "- 25% are relevant to the general topic\n",
    "- < 10% of those fill the distant cells of the typology\n",
    "- 40 weeks to get a single example for 1 cell in the typology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data acquistion: gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/babel2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data acquisition: explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/fedden.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/newscan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/oldscan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/oldscanbad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Images/oldscan3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Different versions of the same document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Filename: Author-TextIDYear-Version.pdf\n",
    "\n",
    "- adelaar-amalgamation-malagasy2010.pdf\n",
    "- adelaar-austronesian2013.pdf\n",
    "- adelaar-austronesian-asia-madagascar2005.pdf\n",
    "- adelaar-austronesian-asia-madagascar2005v2.pdf\n",
    "- adelaar-austronesian-historical2005.pdf\n",
    "- adelaar-austronesian-historical2005-o.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data understanding report\n",
    "\n",
    "- 10000 > PDFs\n",
    "    - The 'best' reference for a language\n",
    "        - Grammars\n",
    "        - Other descriptive materials\n",
    "- Majority OCR’d\n",
    "    - Already searchable\n",
    "- Varying quality and sources\n",
    "    - Fairly messy and difficult to access\n",
    "- Lots of duplicate files\n",
    "    - Best files have the longest name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data acquisition: update the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we can search the data we need to:\n",
    "\n",
    "Step 1 - Clean up the PDFs\n",
    "- Sort the collection\n",
    "- Remove bad candidates for searching\n",
    "\n",
    "Step 2 - Extract the text\n",
    "- Existing tool pdftotext.exe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 1 - Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we handle repeated ﬁles?\n",
    "\n",
    "Filename: Author-TextIDYear-Version.pdf\n",
    "\n",
    "- adelaar-amalgamation-malagasy2010.pdf\n",
    "- adelaar-austronesian2013.pdf\n",
    "- adelaar-austronesian-asia-madagascar2005.pdf\n",
    "- adelaar-austronesian-asia-madagascar2005v2.pdf\n",
    "- adelaar-austronesian-historical2005.pdf\n",
    "- adelaar-austronesian-historical2005-o.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Import the packages we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our folder containing pdfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pdfdir = os.listdir('./grammars/pdfs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want the longest file names:\n",
    "\n",
    "Find files whose names are a substring of another file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subsetlst = []\n",
    "\n",
    "for file in pdfdir:\n",
    "    filestring = file[0:-4] + '.+' + '\\.pdf'\n",
    "    regex = re.compile(filestring) # <filename>.+\\.pdf\n",
    "    for file2 in pdfdir:\n",
    "        if regex.match(file2):\n",
    "            subsetlst.append(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsetlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subsetlst2 = []\n",
    "\n",
    "for file in pdfdir:\n",
    "    filestring = file[0:-4] \n",
    "    for file2 in pdfdir:\n",
    "        file2string = file2[0:-4]\n",
    "        if filestring == file2string: \n",
    "            pass\n",
    "        elif filestring in file2string: \n",
    "            subsetlst2.append(file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Make a list of the files whose names aren't a subset of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "uniqlst = []     \n",
    "\n",
    "for file in pdfdir:\n",
    "    if file not in subsetlst:\n",
    "        uniqlst.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniqlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Quality analyser\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How do we work out what is a good quality pdf?\n",
    "- High quality scans ≠ Good quality OCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"Images/goodscan.png\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we work out what is a good quality pdf?\n",
    "- Clear text on white pages\n",
    "- Prefer generated PDFs\n",
    "- Very clean scans on text mode\n",
    "- Lower file sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "pdfqual:\n",
    "\n",
    "- File size / Number of pages\n",
    "- Asks for a threshold (20,000 default)\n",
    "- Prints out a list of the files from the previous list of all pdfs which are < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter quality threshold in bytes (Basic 20000): 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "threshold = input('Enter quality threshold in bytes (Basic 20000): ')\n",
    "\n",
    "cleanpdfs = []\n",
    "\n",
    "for file in uniqlst:\n",
    "    pdf = PdfFileReader('./grammars/pdfs/' + file,)\n",
    "    pages = pdf.getNumPages()\n",
    "    size = os.stat('./grammars/pdfs/' + file).st_size\n",
    "    qual = size / pages\n",
    "    if qual < float(threshold):\n",
    "        cleanpdfs.append((str(file),str(qual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleanpdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2 - Scrape the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "`for /F \"tokens=1\" %%A in (.\\statfile.tsv) do .\\pdftotext.exe -enc UTF-8 ..\\pdfs\\%%A .\\texts\\%%A.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gather the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='Images/data.png' width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Search for the same gloss twice in the one word*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "leipzig = ['1','2','3','1SG','1DU', '1DL','1PL','2SG','2DU','2DL','2PL' '3SG','3DU','3DL','3PL','ABE','ABL','ABS','ACC','ACCOM','ACT','ADJ','ADE','ADM','ADV','AFF','AG','AGT','AGR','ALL','AL','ALLOC','ALIEN','AN','AND','ANT','ANTE','ANTIC','ANTIP','AP','AOR','APP','APL','APPL','APPR','APRX','ART','ASP','ASS','AT','ATT','AUD','AUG','AUX','BEN','CAP','CAU','CAUS','CENT','CF','CL','CNSQ','COL','COM','COMP','COMPL','CPL','CONC','COND','CONJ','CONT','CTN','CNTR','COP','COR','CRAS','CRS','DAT','DE','DEC','DECL','DEF','DEL','DEL','DEO','DEP','DES','DESI','DEST','DIM','DIR','DISJ','DIST','DISTR','DITR','DLM','DU','DUB','DUR','DY','DYAD','DYN','ELA','EMP','EPIS','ERG','ESS','EV','EVID','EVIT','EX','EXCL','EXCLAM','DUR','EXESS','EXH','EXIST','EXO','EXP','EXPER','FEM','FACT','FOC','FORM','FP','FR','FREQ','FUT','GEN','GER','GNO','GT','HAB','HBL','HEST','HIST','HOD','HON','HORT','HSY','HUM','HYP','IGNOR','ILL','IMM','IMP','IMPERF','IMPR','IMPREC','INCH','INCHO','INCEP','IND','INDF','NDEF','INE','INF','INFER','INFR','INEL','INS','INSTR','INT','NTR','INV','IO','IPFV','IRR','IS','ITER','JUS','LAT','LD','LOC','LOG','MASC','MID','MIM','MIR','MLT','MLTP','MOD','MOM','NEUT','NEG','NMZ','NZ','NOMI','NOM','NS','NUM','OBJ','OB','OBL','OBV','OPT','PART','PAS','PASS','PAT','PA','PAU','PEG','PER','PERF','PRF','PERS','PFV','PL','PLU','PLUR','PN','PRO','PO','POL','POS','POSS','POST','POSTE','POSTEL','POT','PP','PPFV','PPP','PR','PREC','PRED','PREP','PRESP','PRET','PRT','PRF','PERF','PRIV','PRS','PRES','PROB','PROG','PROH','PROL','PROP','PROS','PROSP','PRSP','PROT','PROX','PST','PT','PTCP','PCP','PTV','PURP','QUOT','REAL','REC','RECP','REF','RFR','REFL','REL','REM','REP','RES','RET','SBJ','SUB','SBJV','SJV','SE','SEM','SENS','SEQ','SG','SGV','SIM','SJV','SBJV','SPEC','SS','STAT','STV','SUB','SU','SUBR','SUBORD','SBRD','SR','SUBE','SUBL','SUC','SUP','SUPE','TAM','TEL','TEMP','TERM','TNS','TOP','TR','TRANS','TRANSL','TRI','TRN','TVF','UH','UND','UR','USIT','VB','VBZ','VD','VEN','VER','VIA','VIS','VI','VN','VOC','VOL','VT','WH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quigley_awara2003_s.pdf.txt\n",
      "pekkanen_clause-tatana1988_o.pdf.txt\n",
      "gamudze_guhu-samane2013_s.pdf.txt\n",
      "bowern_bardi2012v2.pdf.txt\n",
      "mohamed_sihan2011.pdf.txt\n",
      "stegeman-hunter_akawaio2014.pdf.txt\n",
      "ballantyne_yapese2005_s.pdf.txt\n",
      "naitoro_areare2013.pdf.txt\n",
      "harvey_gaagudju1992v2.pdf.txt\n",
      "foley_yimas1991.pdf.txt\n",
      "fedden_mian2011v2.pdf.txt\n",
      "hardin_maia2002.pdf.txt\n",
      "campbell_giimbiyu2006_o.pdf.txt\n",
      "aikhenvald_tariana1999_s.pdf.txt\n",
      "thoron_kichua1886.pdf.txt\n",
      "sanders-sanders_kamasau1987.pdf.txt\n",
      "zeitoun_rukai2005.pdf.txt\n",
      "toland-toland_karo-rawa1991.pdf.txt\n",
      "vandervoort_koaia2000.pdf.txt\n",
      "fleischmann-turpeinen_bine1977.pdf.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"multiple_exponence.tsv\", 'w') as results:\n",
    "    for lang in os.listdir('./grammars/texts/'):\n",
    "        print(lang) #provides feedback so we can see this\n",
    "        for gloss in leipzig:\n",
    "            page = 1\n",
    "            linenum = 0 \n",
    "            rex1 = str(gloss) + \"[\\|\\\\\\.\\-][^\\d\\s]+[\\|\\\\\\.\\-]\" + str(gloss) \n",
    "            rex2 = \"[^\\d][\\|\\\\\\.\\-]?\" + str(gloss) + \"\\-\" + str(gloss) + \"[\\|\\\\\\.\\-]?[^\\d]\"\n",
    "            regex = \"(\" + rex1 + \")|(\" + rex2 + \")\"\n",
    "            filename = './grammars/texts/' + lang\n",
    "            with open(filename) as file:\n",
    "                for line in file:\n",
    "                    if '\\x0c' in line:\n",
    "                        page = page + 1\n",
    "                        continue\n",
    "                    linenum = linenum + 1\n",
    "                    glossline = re.findall(regex, line)# To ignorecase: add after comma in parenth: flags=re.IGNORECASE\n",
    "                    for thing in glossline:\n",
    "                        output = str(gloss) + '\\t' + lang + '\\t' + str(linenum) + '\\t' + str(page) + '\\t' + str(line) \n",
    "                        results.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='Images/data.png' width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### pandas\n",
    "\n",
    "- Data analysis-software library for Python\n",
    "- R users = 'dplyr'\n",
    "- MS Excel for Python\n",
    "- Uses dataframes for the manipulation and analysis of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "me_df = pd.read_csv(\"multiple_exponence.tsv\",\n",
    "                 sep='\\t',\n",
    "                 names=[\"Gloss\", \"File\", \"Line\", \"Page\", \"Match\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gloss</th>\n",
       "      <th>File</th>\n",
       "      <th>Line</th>\n",
       "      <th>Page</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28250</td>\n",
       "      <td>781</td>\n",
       "      <td>splash=TEMP 1-PST-1AUG-do/say-CONT-REM.PST sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28261</td>\n",
       "      <td>782</td>\n",
       "      <td>1-PST-1AUG-do/say-CONT-REM.PST ﬁsh=TEMP one.place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28275</td>\n",
       "      <td>782</td>\n",
       "      <td>1-PST-1AUG-wait.for-CONT-REM.PST tide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28297</td>\n",
       "      <td>782</td>\n",
       "      <td>1-PST-1AUG-kill-CONT-REM.PST=3A.DO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28303</td>\n",
       "      <td>782</td>\n",
       "      <td>Barda=gid a-ng-arr-a-na-n=irr away=TEMP 1-PST-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28366</td>\n",
       "      <td>783</td>\n",
       "      <td>1-FUT-1AUG-take-FUT=2M.DO off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>28383</td>\n",
       "      <td>784</td>\n",
       "      <td>2M 1-FUT-1AUG-take-FUT=2M.DO off go=REL away off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>4053</td>\n",
       "      <td>164</td>\n",
       "      <td>pur i-n-­cal=­cir look 3-TR-see-3A.IO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>6311</td>\n",
       "      <td>240</td>\n",
       "      <td>clean’im 3-PST-put-REM.PST-3A.DO this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>6467</td>\n",
       "      <td>245</td>\n",
       "      <td>3-PST-AUG-put-REM.PST-REL-INDF-3A.DO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>11965</td>\n",
       "      <td>377</td>\n",
       "      <td>spear.tip 3-M.POSS-3AUG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>12642</td>\n",
       "      <td>394</td>\n",
       "      <td>clean’im 3-PST-put-REM.PST-3A.DO this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>13571</td>\n",
       "      <td>417</td>\n",
       "      <td>3-AUG-fear-CONT-3M.IO-1M.POSS woman’s.child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>15617</td>\n",
       "      <td>462</td>\n",
       "      <td>wife 3-[PST]-TR-[give]-3M.IO=3M.POSS ﬁsh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>17084</td>\n",
       "      <td>502</td>\n",
       "      <td>very 3-AUG-stomach-3A.IO child-ERG good food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALL</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>12563</td>\n",
       "      <td>391</td>\n",
       "      <td>3-TR-send-REDUP-CONT=3A.DO place-ALL-place-ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AUG</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>10747</td>\n",
       "      <td>349</td>\n",
       "      <td>NEG 2AUG-IRR-AUG-be.frightened-FUT=1MIN.IO 1MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AUG</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>12987</td>\n",
       "      <td>402</td>\n",
       "      <td>NEG 2AUG-IRR-AUG-be.frightened-FUT=1M.IO 1MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FUT</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>2393</td>\n",
       "      <td>111</td>\n",
       "      <td>(2.8) a. Garrma ngankalarri. Garrma nga-n-k-al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FUT</td>\n",
       "      <td>bowern_bardi2012v2.pdf.txt</td>\n",
       "      <td>4427</td>\n",
       "      <td>179</td>\n",
       "      <td>a. oo-ngg-oorr-andoor-a 3-FUT-AUG-wade.across-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gloss                        File   Line  Page  \\\n",
       "0      1  bowern_bardi2012v2.pdf.txt  28250   781   \n",
       "1      1  bowern_bardi2012v2.pdf.txt  28261   782   \n",
       "2      1  bowern_bardi2012v2.pdf.txt  28275   782   \n",
       "3      1  bowern_bardi2012v2.pdf.txt  28297   782   \n",
       "4      1  bowern_bardi2012v2.pdf.txt  28303   782   \n",
       "5      1  bowern_bardi2012v2.pdf.txt  28366   783   \n",
       "6      1  bowern_bardi2012v2.pdf.txt  28383   784   \n",
       "7      3  bowern_bardi2012v2.pdf.txt   4053   164   \n",
       "8      3  bowern_bardi2012v2.pdf.txt   6311   240   \n",
       "9      3  bowern_bardi2012v2.pdf.txt   6467   245   \n",
       "10     3  bowern_bardi2012v2.pdf.txt  11965   377   \n",
       "11     3  bowern_bardi2012v2.pdf.txt  12642   394   \n",
       "12     3  bowern_bardi2012v2.pdf.txt  13571   417   \n",
       "13     3  bowern_bardi2012v2.pdf.txt  15617   462   \n",
       "14     3  bowern_bardi2012v2.pdf.txt  17084   502   \n",
       "15   ALL  bowern_bardi2012v2.pdf.txt  12563   391   \n",
       "16   AUG  bowern_bardi2012v2.pdf.txt  10747   349   \n",
       "17   AUG  bowern_bardi2012v2.pdf.txt  12987   402   \n",
       "18   FUT  bowern_bardi2012v2.pdf.txt   2393   111   \n",
       "19   FUT  bowern_bardi2012v2.pdf.txt   4427   179   \n",
       "\n",
       "                                                Match  \n",
       "0   splash=TEMP 1-PST-1AUG-do/say-CONT-REM.PST sal...  \n",
       "1   1-PST-1AUG-do/say-CONT-REM.PST ﬁsh=TEMP one.place  \n",
       "2               1-PST-1AUG-wait.for-CONT-REM.PST tide  \n",
       "3                  1-PST-1AUG-kill-CONT-REM.PST=3A.DO  \n",
       "4   Barda=gid a-ng-arr-a-na-n=irr away=TEMP 1-PST-...  \n",
       "5                       1-FUT-1AUG-take-FUT=2M.DO off  \n",
       "6    2M 1-FUT-1AUG-take-FUT=2M.DO off go=REL away off  \n",
       "7               pur i-n-­cal=­cir look 3-TR-see-3A.IO  \n",
       "8               clean’im 3-PST-put-REM.PST-3A.DO this  \n",
       "9                3-PST-AUG-put-REM.PST-REL-INDF-3A.DO  \n",
       "10                            spear.tip 3-M.POSS-3AUG  \n",
       "11              clean’im 3-PST-put-REM.PST-3A.DO this  \n",
       "12        3-AUG-fear-CONT-3M.IO-1M.POSS woman’s.child  \n",
       "13          wife 3-[PST]-TR-[give]-3M.IO=3M.POSS ﬁsh.  \n",
       "14       very 3-AUG-stomach-3A.IO child-ERG good food  \n",
       "15     3-TR-send-REDUP-CONT=3A.DO place-ALL-place-ALL  \n",
       "16    NEG 2AUG-IRR-AUG-be.frightened-FUT=1MIN.IO 1MIN  \n",
       "17      NEG 2AUG-IRR-AUG-be.frightened-FUT=1M.IO 1MIN  \n",
       "18  (2.8) a. Garrma ngankalarri. Garrma nga-n-k-al...  \n",
       "19  a. oo-ngg-oorr-andoor-a 3-FUT-AUG-wade.across-...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(me_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1270.000000</td>\n",
       "      <td>1270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15667.544882</td>\n",
       "      <td>401.680315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7531.868969</td>\n",
       "      <td>208.434678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9524.500000</td>\n",
       "      <td>244.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16008.000000</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22272.250000</td>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33235.000000</td>\n",
       "      <td>807.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Line         Page\n",
       "count   1270.000000  1270.000000\n",
       "mean   15667.544882   401.680315\n",
       "std     7531.868969   208.434678\n",
       "min      105.000000     8.000000\n",
       "25%     9524.500000   244.250000\n",
       "50%    16008.000000   397.000000\n",
       "75%    22272.250000   550.000000\n",
       "max    33235.000000   807.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(me_df[\"File\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File\n",
       "aikhenvald_tariana1999_s.pdf.txt    119\n",
       "bowern_bardi2012v2.pdf.txt          535\n",
       "campbell_giimbiyu2006_o.pdf.txt      10\n",
       "fedden_mian2011v2.pdf.txt           468\n",
       "foley_yimas1991.pdf.txt              71\n",
       "hardin_maia2002.pdf.txt              17\n",
       "harvey_gaagudju1992v2.pdf.txt        46\n",
       "naitoro_areare2013.pdf.txt            3\n",
       "zeitoun_rukai2005.pdf.txt             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_df.groupby('File').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gloss</th>\n",
       "      <th>File</th>\n",
       "      <th>Line</th>\n",
       "      <th>Page</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>749</td>\n",
       "      <td>23</td>\n",
       "      <td>1s=TP talk PROX=MN return-CAU1-IR.1s 2p-heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>789</td>\n",
       "      <td>24</td>\n",
       "      <td>49) wi=nor saki saki-arav=o me+da sarar duwa=g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1011</td>\n",
       "      <td>29</td>\n",
       "      <td>work-VR1-IPF-RL.1s/3p D1 a.little=LIM talk-VR1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1025</td>\n",
       "      <td>29</td>\n",
       "      <td>lamua-t-io.\" bad-CAU1-IR.1s ‘If I see just 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1147</td>\n",
       "      <td>32</td>\n",
       "      <td>tomato 3s-DAT a.steal-VR1-RL.1p SS run.away-SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1355</td>\n",
       "      <td>36</td>\n",
       "      <td>talk do-MN talk-VR1-RL.1s/3p=TP=EM talk NEG+AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1784</td>\n",
       "      <td>45</td>\n",
       "      <td>imar-a-go-mo assembly-VR1-IPF-1s/3p ‘they were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>1863</td>\n",
       "      <td>47</td>\n",
       "      <td>165) Awun maia=di ono=ra sinam-tato-mo. dog PL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>2299</td>\n",
       "      <td>55</td>\n",
       "      <td>210) Yo yo-nor emuar=at dumag avia-mi tete ono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>4104</td>\n",
       "      <td>95</td>\n",
       "      <td>407) Yo yo-nor emuar=at dumag avia-mi tete ono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>4943</td>\n",
       "      <td>114</td>\n",
       "      <td>time/day some/other=TP man woman PL 3p-eye=LOC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>4991</td>\n",
       "      <td>115</td>\n",
       "      <td>...tree surface.roots big 3s-INTP D1=LOC2 stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>6079</td>\n",
       "      <td>134</td>\n",
       "      <td>2p=TP tomorrow Dugamor=LOC2 meet-SEQ chicken s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>6121</td>\n",
       "      <td>135</td>\n",
       "      <td>666) Yo [ u-nau Kaukambar=ga wake kani ig-a on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>6326</td>\n",
       "      <td>139</td>\n",
       "      <td>story small story-VR1-PROS-RL.1s/3p now/today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>3</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>4137</td>\n",
       "      <td>96</td>\n",
       "      <td>...water mouth=LOC1 be-RL.3s D1 spill-CAU3-RL.3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>3</td>\n",
       "      <td>hardin_maia2002.pdf.txt</td>\n",
       "      <td>6130</td>\n",
       "      <td>135</td>\n",
       "      <td>...water mouth=LOC1 be-RL.3s D1 3s-spill-CAU3-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gloss                     File  Line  Page  \\\n",
       "1123     1  hardin_maia2002.pdf.txt   749    23   \n",
       "1124     1  hardin_maia2002.pdf.txt   789    24   \n",
       "1125     1  hardin_maia2002.pdf.txt  1011    29   \n",
       "1126     1  hardin_maia2002.pdf.txt  1025    29   \n",
       "1127     1  hardin_maia2002.pdf.txt  1147    32   \n",
       "1128     1  hardin_maia2002.pdf.txt  1355    36   \n",
       "1129     1  hardin_maia2002.pdf.txt  1784    45   \n",
       "1130     1  hardin_maia2002.pdf.txt  1863    47   \n",
       "1131     1  hardin_maia2002.pdf.txt  2299    55   \n",
       "1132     1  hardin_maia2002.pdf.txt  4104    95   \n",
       "1133     1  hardin_maia2002.pdf.txt  4943   114   \n",
       "1134     1  hardin_maia2002.pdf.txt  4991   115   \n",
       "1135     1  hardin_maia2002.pdf.txt  6079   134   \n",
       "1136     1  hardin_maia2002.pdf.txt  6121   135   \n",
       "1137     1  hardin_maia2002.pdf.txt  6326   139   \n",
       "1138     3  hardin_maia2002.pdf.txt  4137    96   \n",
       "1139     3  hardin_maia2002.pdf.txt  6130   135   \n",
       "\n",
       "                                                  Match  \n",
       "1123  1s=TP talk PROX=MN return-CAU1-IR.1s 2p-heart ...  \n",
       "1124  49) wi=nor saki saki-arav=o me+da sarar duwa=g...  \n",
       "1125  work-VR1-IPF-RL.1s/3p D1 a.little=LIM talk-VR1...  \n",
       "1126  lamua-t-io.\" bad-CAU1-IR.1s ‘If I see just 40 ...  \n",
       "1127  tomato 3s-DAT a.steal-VR1-RL.1p SS run.away-SE...  \n",
       "1128  talk do-MN talk-VR1-RL.1s/3p=TP=EM talk NEG+AD...  \n",
       "1129  imar-a-go-mo assembly-VR1-IPF-1s/3p ‘they were...  \n",
       "1130  165) Awun maia=di ono=ra sinam-tato-mo. dog PL...  \n",
       "1131  210) Yo yo-nor emuar=at dumag avia-mi tete ono...  \n",
       "1132  407) Yo yo-nor emuar=at dumag avia-mi tete ono...  \n",
       "1133  time/day some/other=TP man woman PL 3p-eye=LOC...  \n",
       "1134  ...tree surface.roots big 3s-INTP D1=LOC2 stan...  \n",
       "1135  2p=TP tomorrow Dugamor=LOC2 meet-SEQ chicken s...  \n",
       "1136  666) Yo [ u-nau Kaukambar=ga wake kani ig-a on...  \n",
       "1137      story small story-VR1-PROS-RL.1s/3p now/today  \n",
       "1138   ...water mouth=LOC1 be-RL.3s D1 spill-CAU3-RL.3s  \n",
       "1139  ...water mouth=LOC1 be-RL.3s D1 3s-spill-CAU3-...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_df[me_df['File'].str.contains('hardin')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropnames = ['hardin', 'natitoro', 'rukai']\n",
    "\n",
    "for name in dropnames:\n",
    "    me_df = me_df[~me_df['File'].str.contains(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(me_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/typscience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://wals.info/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://www.smg.surrey.ac.uk/syncretism/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://lexicalsplitsdb.surrey.ac.uk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://github.com/autotyp/autotyp-data/tree/0.1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://zenodo.org/record/4898419#.Yas2mNBByUk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://sacha.beniamine.net/dataset/beniamine-maiden-round-2019/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://www.gerlingo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Move away from *databases* and toward *datasets*\n",
    "\n",
    "- Data set is a collection of data in a tabular format\n",
    "- Query the data directly\n",
    "- Generalisable across projects\n",
    "- As close to language data as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data/Code Sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Images/typscience.jpg\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why share your data and code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Reproducibility\n",
    "2. Journals require it\n",
    "3. Learn a lot\n",
    "4. Extends the impact of your project\n",
    "5. Build a portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "‘FAIR Guiding Principles for scientific data management and stewardship’ were published in *Scientific Data 2006*. https://www.go-fair.org/fair-principles/\n",
    "\n",
    "\n",
    "**F**indable\n",
    "- Will anyone else know that your data exists?\n",
    "    - Solutions: put it in a standard repository, or at least a description of the data. Get a digital object identifier (DOI).\n",
    "    \n",
    "**A**ccessible\n",
    "- Once someone knows that the data exists, can they get it?\n",
    "    - Usually solved by being in a repository, but for non-open data, may require more procedures.\n",
    "\n",
    "**I**nteroperable\n",
    "-  your data in a format that can be used by others, like csv instead of PDF?\n",
    "\n",
    "**R**eusable\n",
    "- Is there a license allowing others to re-use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sharing on Zenodo\n",
    "\n",
    "Directly:\n",
    "- Easy\n",
    "- Good for finalised datasets that wont change\n",
    "\n",
    "Github:\n",
    "- A couple more steps\n",
    "- Allows version control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://zenodo.org/\n",
    "\n",
    "https://sandbox.zenodo.org/login/\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
